# Эмулятор кэш-памяти: стратегии LRU и LFU

## Оглавление
1. [Введение](#введение)
2. [Алгоритмы кэширования](#алгоритмы-кэширования)
3. [Структура проекта](#структура-проекта)
4. [Принципы работы](#принципы-работы)
5. [Реализации](#реализации)
6. [Метрики производительности](#метрики-производительности)
7. [Сборка и запуск](#сборка-и-запуск)
8. [Результаты тестирования](#результаты-тестирования)
9. [Выводы](#выводы)

## Введение

Этот проект реализует эмулятор кэш-памяти с двумя стратегиями вытеснения: **LRU (Least Recently Used)** и **LFU (Least Frequently Used)**. Каждая стратегия реализована в двух вариантах: **итеративном** и **рекурсивном**.

## Алгоритмы кэширования

### LRU (Least Recently Used)
**Принцип:** Вытесняет самый давно неиспользуемый элемент.

**Логика работы:**
- При доступе к существующему элементу он перемещается в начало списка
- При добавлении нового элемента:
  - Если кэш полон, удаляется последний элемент списка
  - Новый элемент добавляется в начало

**Пример из кода:**
```cpp
// LRU итеративный get
int lru_get_iterative(Cache* cache, int key) {
    CacheNode* current = cache->head;
    while (current) {
        if (current->key == key) {
            moveToFront(cache, current);  // Перемещаем в начало
            return current->value;
        }
        current = current->next;
    }
    return -1;
}
```

### LFU (Least Frequently Used)
**Принцип:** Вытесняет самый редко используемый элемент.

**Логика работы:**
- Каждый элемент имеет счетчик частоты использования
- При доступе к элементу увеличивается его счетчик частоты
- При добавлении нового элемента:
  - Если кэш полон, ищется элемент с минимальной частотой использования
  - Удаляется элемент с наименьшей частотой

**Пример из кода:**
```cpp
// LFU итеративный put
void lfu_put_iterative(Cache* cache, int key, int value) {
    // Поиск элемента с минимальной частотой
    CacheNode* leastFrequent = cache->head;
    CacheNode* current = cache->head;
    while (current) {
        if (current->frequency < leastFrequent->frequency) {
            leastFrequent = current;
        }
        current = current->next;
    }
    // Удаление наименее используемого элемента
    removeNode(cache, leastFrequent);
    delete leastFrequent;
}
```

## Структура проекта

```
cache_emulator/
├── cache.h           // Основные структуры и объявления функций
├── cache.cpp         // Реализации LRU/LFU (итеративные и рекурсивные)
├── metrics.h         // Структуры для сбора метрик
├── metrics.cpp       // Реализация функций метрик
├── main.cpp          // Основная программа с тестами
├── test_comparison.cpp // Тесты сравнения производительности
├── extended_test.cpp   // Расширенные тесты
└── Makefile          // Файл сборки
```

## Принципы работы

### Базовая структура данных
Проект использует **двусвязный список** для хранения элементов кэша:

```cpp
struct CacheNode {
    int key;
    int value;
    int frequency;      // Для LFU
    CacheNode* next;
    CacheNode* prev;
};

struct Cache {
    CacheNode* head;
    CacheNode* tail;
    size_t capacity;
    size_t size;
    bool is_lru;        // true для LRU, false для LFU
};
```

### Ключевые операции со списком

1. **Добавление в начало:**
```cpp
void addToFront(Cache* cache, CacheNode* node) {
    node->next = cache->head;
    node->prev = nullptr;
    if (cache->head) {
        cache->head->prev = node;
    }
    cache->head = node;
    cache->size++;
}
```

2. **Удаление элемента:**
```cpp
void removeNode(Cache* cache, CacheNode* node) {
    if (node->prev) node->prev->next = node->next;
    else cache->head = node->next;

    if (node->next) node->next->prev = node->prev;
    else cache->tail = node->prev;

    cache->size--;
}
```

## Реализации

### Итеративный подход
Использует циклы для обхода списка. Более эффективен по памяти и времени выполнения.

**Преимущества:**
- Меньший расход стека
- Предсказуемое поведение
- Лучшая производительность

### Рекурсивный подход
Использует рекурсивные вызовы для обхода списка. Демонстрирует альтернативный стиль программирования.

**Пример рекурсивного поиска в LRU:**
```cpp
CacheNode* lru_find_recursive(CacheNode* current, int key) {
    if (!current) return nullptr;
    if (current->key == key) return current;
    return lru_find_recursive(current->next, key);
}
```

**Особенности рекурсивного подхода в LFU:**
```cpp
CacheNode* lfu_find_least_frequent_recursive(CacheNode* current, CacheNode* min_node) {
    if (!current) return min_node;
    if (current->frequency < min_node->frequency) {
        min_node = current;
    }
    return lfu_find_least_frequent_recursive(current->next, min_node);
}
```

## Метрики производительности

Проект включает систему сбора метрик для оценки эффективности алгоритмов:

```cpp
struct CacheMetrics {
    size_t hits = 0;
    size_t misses = 0;
    size_t total_operations = 0;

    double hit_rate() const {
        return (static_cast<double>(hits) / total_operations) * 100.0;
    }
};
```

**Ключевые метрики:**
- **Hit Rate**: Процент успешных обращений к кэшу
- **Miss Rate**: Процент промахов кэша
- **Время выполнения**: Сравнение производительности подходов

## Сборка и запуск

### Сборка проекта:
```bash
make
```

### Запуск основных тестов:
```bash
./cache_emulator
```

### Запуск тестов сравнения:
```bash
g++ -std=c++11 -Wall test_comparison.cpp cache.cpp metrics.cpp -o test_comparison
./test_comparison
```

### Запуск расширенных тестов:
```bash
g++ -std=c++11 -Wall extended_test.cpp cache.cpp metrics.cpp -o extended_test
./extended_test
```

## Результаты тестирования

# Объяснение процента промахов (Miss Rate) в контексте корректно работающего алгоритма

## Фундаментальное понимание промахов

**Важный момент:** Наличие промахов **не означает** ошибку в алгоритме! Напротив - это **неотъемлемая и ожидаемая** часть работы любого кэша.

## Аналогия для понимания

Представьте библиотеку с ограниченным количеством полок (кэш) и огромным книгохранилищем (медленная память):

- **Попадание (Hit)** - книга уже на полке, берем мгновенно ✅
- **Промах (Miss)** - книги нет на полке, идем в хранилище ⏱️

**Промахи неизбежны**, потому что:
- Полок меньше, чем книг
- Мы не можем угадать все будущие запросы
- Некоторые книги запрашиваются редко

## Математическая неизбежность промахов

### Для кэша размера `C` и `N` уникальных ключей:
- Если `N > C` (что почти всегда верно), то промахи **неизбежны**
- Даже идеальный алгоритм будет иметь промахи
- **Цель** - минимизировать промахи, а не устранить их полностью

## Пример из нашего кода

```cpp
// Эта функция ВСЕГДА будет возвращать -1 при промахе
// Это НОРМАЛЬНОЕ поведение, а не ошибка!
int lru_get_iterative(Cache* cache, int key) {
    CacheNode* current = cache->head;
    while (current) {
        if (current->key == key) {
            moveToFront(cache, current);
            return current->value;  // ПОПАДАНИЕ
        }
        current = current->next;
    }
    return -1;  // ПРОМАХ - это корректный результат!
}
```

## Почему промахи - это хорошо?

### 1. **Доказательство работы алгоритма**
Если бы промахов не было вообще, это означало бы что:
- Либо кэш бесконечно большого размера (невозможно)
- Либо алгоритм не работает (например, всегда возвращает попадание)

### 2. **Инструмент оптимизации**
Анализ промахов помогает:
- Подобрать оптимальный размер кэша
- Выбрать лучшую стратегию вытеснения
- Понимать паттерны доступа к данным

### 3. **Естественное ограничение систем**
```cpp
// При добавлении нового элемента в полный кэш
if (cache->size >= cache->capacity) {
    // ВЫТЕСНЕНИЕ - создает будущие промахи
    removeNode(cache, cache->tail);
}
// Но без вытеснения мы не сможем добавить новые данные!
```

## Интерпретация процента промахов

### Хорошие показатели:
- **5-20% промахов** - отличная эффективность
- **20-50% промахов** - нормальная работа
- **>50% промахов** - стоит пересмотреть стратегию или размер

### Из наших тестов:
```
LRU: Hit Rate = 49.6%, Miss Rate = 50.4%
LFU: Hit Rate = 51%, Miss Rate = 49%
```

Это **нормальные показатели** для:
- Случайного паттерна запросов
- Ограниченного размера кэша
- Реалистичных условий работы

## Когда беспокоиться о промахах?

Только если:
1. **Miss Rate = 100%** - кэш никогда не используется
2. **Miss Rate = 0%** - подозрение на ошибку в логике
3. **Резкий рост** промахов без изменения нагрузки

## Практический пример

```cpp
// Тест: последовательность 1,2,3,4,5 с кэшем размера 3
Cache* cache = create_cache(3, true);

// Все эти операции вызовут промахи (и это нормально!)
lru_put(cache, 1, 100); // Miss - кэш пустой
lru_put(cache, 2, 200); // Miss - добавляем второй элемент
lru_put(cache, 3, 300); // Miss - добавляем третий элемент
lru_put(cache, 4, 400); // Miss - вытесняем 1, добавляем 4
lru_put(cache, 5, 500); // Miss - вытесняем 2, добавляем 5

// Но теперь некоторые запросы будут попаданиями
lru_get(cache, 3); // Hit - элемент 3 еще в кэше
lru_get(cache, 1); // Miss - элемент 1 был вытеснен ранее
```

## Вывод

**Промахи - это не баг, а фича!** Они:
- ✅ Доказывают, что алгоритм работает правильно
- ✅ Показывают, что кэш имеет ограниченный размер
- ✅ Помогают анализировать эффективность стратегии
- ✅ Отражают реальные ограничения компьютерных систем

**Идеальный кэш** - не тот, у которого нет промахов (это невозможно), а тот, у которого промахи **минимальны для данной нагрузки и размера**.

### Производительность на 1000 операций:
- **LRU Итеративный**: 42μs, Hit Rate: 49.6%
- **LRU Рекурсивный**: 58μs, Hit Rate: 49.6%
- **LFU Итеративный**: 52μs, Hit Rate: 51%
- **LFU Рекурсивный**: 64μs, Hit Rate: 51%

### Ключевые наблюдения:
1. **Итеративные подходы на 20-40% быстрее** рекурсивных
2. **LFU показывает лучшую эффективность** при частых повторениях
3. **Рекурсивные подходы дают идентичные результаты**, но с накладными расходами

## Выводы

### Вычислительная сложность:
- **Все алгоритмы**: O(n) для поиска в худшем случае
- **Итеративные подходы**: Лучшая производительность на практике
- **Рекурсивные подходы**: Демонстрация альтернативной парадигмы

### Рекомендации по использованию:
- **LRU**: Эффективен для данных с временной локальностью
- **LFU**: Лучше подходит для workload'ов с частыми повторениями
- **Итеративная реализация**: Предпочтительна для production-систем
- **Рекурсивная реализация**: Полезна для обучения и демонстрации

### Образовательная ценность:
Проект демонстрирует:
- Различные стратегии управления памятью
- Сравнение итеративного и рекурсивного мышления
- Практическое применение структур данных
- Методы оценки производительности алгоритмов

Проект успешно выполняет все поставленные задачи семинара и предоставляет прочную основу для понимания принципов кэширования и различных подходов к реализации алгоритмов.
